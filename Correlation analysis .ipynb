{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54111b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "# Load water company data as wrz, remove unnecessary columns\n",
    "wrz = gpd.read_file(os.path.abspath('data_files/WaterSupplyAreas_incNAVs v1_4.shp'))\n",
    "# List of columns to be removed\n",
    "columns_to_remove = ['Disclaimer', 'Disclaim2', 'Disclaim3', 'Provenance', 'Licence', 'WARNINGS', 'Revisions', 'AreaServed']\n",
    "\n",
    "# Drop the columns from the GeoDataFrame\n",
    "wrz = wrz.drop(columns=columns_to_remove)\n",
    "\n",
    "included_area_types = ['regional water and sewerage company', 'regional water only company'] # Filter the GeoDataFrame to select the features with \"Northumbrian Water\"\n",
    "\n",
    "wrz['COMPANY'] = wrz['COMPANY'].replace('Northumbrian Water Limited', 'Northumbrian Water') # fix issue with NES record\n",
    "\n",
    "# Filter out features with the specified area types\n",
    "wrz_ref = wrz[wrz['CoType'].isin(included_area_types)]\n",
    " # len(wrz_ref) # uncomment this to check that all 43 water company areas are included \n",
    "wrz_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0b8f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by the 'Company' column\n",
    "grouped_wrz = wrz.groupby('COMPANY')\n",
    "\n",
    "# Create an empty GeoSeries to store the unioned geometries\n",
    "merged_geometries = gpd.GeoSeries()\n",
    "acronyms = []\n",
    "\n",
    "# Iterate over each group and perform the union operation\n",
    "for group_name, group_data in grouped_wrz:\n",
    "    unioned_geometry = group_data['geometry'].unary_union\n",
    "    merged_geometries[group_name] = unioned_geometry\n",
    "    acronyms.append(group_data['Acronym'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efde4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new GeoDataFrame with the unioned geometries for each company\n",
    "merged_wrz_companies = gpd.GeoDataFrame(geometry=merged_geometries.values, index=merged_geometries.index)\n",
    "merged_wrz_companies['COMPANY'] = merged_geometries.index\n",
    "merged_wrz_companies['Acronym'] = acronyms\n",
    "\n",
    "merged_wrz_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b68068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append Correlation data to the wrz geodataframe\n",
    "# Load the CSV file\n",
    "correlation_data = pd.read_csv('data_files/correlation_data.csv', thousands=',')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbc5bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827d5ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the merge\n",
    "correlate = merged_wrz_companies.merge(correlation_data[['Company', 'hh_cons', 'hh_pop']], how='left', left_on='Acronym', right_on='Company')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cfc2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlate.to_file('data_files_correlate.shp')\n",
    "correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6c2c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c4a6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the hh_pop and hh_cons columns to numeric\n",
    "correlate['hh_pop'] = pd.to_numeric(correlate['hh_pop'], errors='coerce')\n",
    "correlate['hh_cons'] = pd.to_numeric(correlate['hh_cons'], errors='coerce')\n",
    "\n",
    "# Filter out NaN values\n",
    "correlate = correlate.dropna()\n",
    "correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eed8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe into series\n",
    "list1 = correlate['hh_pop']\n",
    "list2 = correlate['hh_cons']\n",
    "\n",
    "# Apply the pearsonr()\n",
    "corr, _ = pearsonr(list1, list2)\n",
    "print('Pearsons correlation: %.3f' % corr)\n",
    "\n",
    "\n",
    "# Convert dataframe into series\n",
    "list1 = correlate['hh_pop']\n",
    "list2 = correlate['hh_cons']\n",
    "\n",
    "# Apply the pearsonr()\n",
    "corr, _ = pearsonr(list1, list2)\n",
    "print('Pearsons correlation: %.3f' % corr)\n",
    "\n",
    "# This code is contributed by Amiya Rout (ref: https://www.geeksforgeeks.org/python-pearson-correlation-test-between-two-variables/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e489a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load landuse data\n",
    "landuse = gpd.read_file(os.path.abspath('data_files/clc2018_uk.shp'))\n",
    "# Load the CSV file\n",
    "landuse_categories = pd.read_csv('data_files/legend.csv')\n",
    "# print(landuse_categories.head())  #show a sample of the CSV file \n",
    "# merge the csv file with the geodataframe to include the labels for the landuse in the geodataframe\n",
    "landuse_categories['CODE'] = landuse_categories['CODE'].astype(str)\n",
    "merged_landuse = pd.merge(landuse, landuse_categories, left_on='CODE_18', right_on='CODE')\n",
    "\n",
    "# Drop unnecessary columns - this cleans the dataset to make it easier to work with\n",
    "merged_landuse = merged_landuse.drop(['CODE_18', 'CODE', 'Unnamed: 4', 'Unnamed: 5'], axis=1)\n",
    "merged_landuse\n",
    "# Access the 'LABEL' column in the merged DataFrame - LABEL gives the actual landuse description\n",
    "label_column = merged_landuse['LABEL']\n",
    "merged_wrz_companies = merged_wrz_companies.set_crs(wrz.crs)\n",
    "print(merged_landuse.crs == merged_wrz_companies.crs) # test if the crs is the same \n",
    "# Perform spatial join between wrz and merged_landuse\n",
    "join = gpd.sjoin(merged_wrz_companies, merged_landuse, how='inner', predicate='intersects')\n",
    "# Group by COMPANY and LABEL, and sum the Area_Ha column\n",
    "grouped = join.groupby(['COMPANY', 'LABEL'])['Area_Ha'].sum().reset_index()\n",
    "\n",
    "# Create a new GeoDataFrame from the grouped data\n",
    "company_landuse = gpd.GeoDataFrame(grouped, geometry=gpd.GeoSeries(), crs=wrz.crs)\n",
    "\n",
    "# Set the geometry of the new GeoDataFrame to the centroid of each LABEL\n",
    "company_landuse.geometry = company_landuse.apply(lambda x: wrz[wrz['COMPANY'] == x['COMPANY']].geometry.centroid.iloc[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb63f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the rows where LABEL includes 'urban'\n",
    "urban_company_landuse = company_landuse[company_landuse['LABEL'].str.contains('urban')]\n",
    "urban_company_landuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef527e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the rows by the COMPANY column and get the sum of the Area_Ha column for each group\n",
    "area_by_company = urban_company_landuse.groupby(\"COMPANY\")[\"Area_Ha\"].sum()\n",
    "\n",
    "# Round the values in the \"Area_Ha\" column to 2 significant digits\n",
    "area_by_company = area_by_company.round(2)\n",
    "\n",
    "# Convert the result to a new GeoDataFrame with a \"COMPANY\" column and an \"AreaHa\" column\n",
    "area_by_company = area_by_company.reset_index()\n",
    "area_by_company.columns = [\"COMPANY\", \"Area_Ha\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f08706",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_by_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73092854",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1def69f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the merge\n",
    "correlate_landuse = correlate.merge(area_by_company[['COMPANY', 'Area_Ha']], how='left', left_on='COMPANY', right_on='COMPANY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlate_landuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7d33c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe into series\n",
    "list2 = correlate_landuse['hh_cons']\n",
    "list3 = correlate_landuse['Area_Ha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12501c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the pearsonr()\n",
    "corr, _ = pearsonr(list2, list3)\n",
    "print('Pearsons correlation: %.3f' % corr)\n",
    "\n",
    "\n",
    "# Convert dataframe into series\n",
    "list2 = correlate_landuse['hh_pop']\n",
    "list3 = correlate_landuse['Area_Ha']\n",
    "\n",
    "# Apply the pearsonr()\n",
    "corr, _ = pearsonr(list2, list3)\n",
    "print('Pearsons correlation: %.3f' % corr)\n",
    "\n",
    "# This code is contributed by Amiya Rout (ref: https://www.geeksforgeeks.org/python-pearson-correlation-test-between-two-variables/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bced54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# household consumption (megalitres per day) divided by Area (Hectares) and converted to Litres per Hectare to give Household consumption per Hectare in Litres per day for land classed as 'urban use'\n",
    "correlate_landuse['hh_cons_per_Area_Ha'] = correlate_landuse['hh_cons'] * 10**6 / 86400 / correlate_landuse['Area_Ha'] * 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5a6f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average household property size in the UK is around 120m "
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ebac5db",
   "metadata": {},
   "source": [
    "correlate_landuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d981e57d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
